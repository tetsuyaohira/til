# LLMのプロンプトエンジニアリング 第1章まとめ

## 1章 プロンプトエンジニアリングの世界

### 1.1 LLMは魔法だ

ChatGPTは2022年11月にリリースされ、翌年1月までに月間利用者数1億人に達し、史上最速で成長した個人向けアプリケーションとなった。この成長速度はTikTok（9ヶ月）やInstagram（2年半）を大幅に上回っている。

ChatGPTを支える大規模言語モデル（LLM）は、私たちの働き方を大きく変えつつある。従来のGoogle検索による情報探索から、LLMへの直接的な質問という形に変化している。技術的な問題に対しても、Stack Overflowやブログ記事を検索する代わりに、LLMに個別のチュートリアル作成や質疑応答を依頼できるようになった。

LLMがこれほど素晴らしい理由は、それが「魔法のような」技術だからである。アーサー・C・クラークの言葉通り、「十分に発達した科学技術は、魔法と見分けがつかない」のである。しかし、LLMの核心部分は単にテキストの次の単語を予測するモデルに過ぎない。

### 1.2 言語モデル：私たちはどのようにたどり着いたのか

#### 初期の言語モデル
2014年までの世界で最も強力な言語モデルは、Googleで導入されたシーケンス・ツー・シーケンス（seq2seq）アーキテクチャに基づいていた。seq2seqは再帰型ニューラルネットワークであり、テキストを1トークンずつ処理し、内部状態を逐次更新する特性を持っていた。

しかし、このアーキテクチャには「情報のボトルネック」という致命的な弱点があった。エンコーダーとデコーダー間での情報伝達が固定サイズの「思考ベクトル」に制限されるため、長いテキストからの重要な情報を「忘れて」しまうことが多かった。

2015年の論文「Neural Machine Translation by Jointly Learning to Align and Translate」では、このボトルネックに対処する新しいアプローチとして「アテンション機構」が紹介された。エンコーダーが単一の思考ベクトルの代わりに、各トークンに対して生成されたすべての隠れ状態ベクトルを保持し、デコーダーがすべてのベクトルに対して「ソフトサーチ」を行えるようにした。

2017年のGoogle Researchの論文「Attention Is All You Need」では、トランスフォーマーアーキテクチャが紹介された。トランスフォーマーは従来のモデルの基本構造を維持しながら、再帰的な回路をすべて取り除き、アテンション機構のみに依存する設計となった。この結果、seq2seqよりも優れた能力を示したが、任意の長さのシーケンスを処理できたseq2seqとは異なり、固定された有限のシーケンスしか処理できないという制限があった。

#### GPTの登場
生成的事前トレーニング済みトランスフォーマー（GPT）アーキテクチャは、2018年の論文「Improving Language Understanding by Generative Pre-Training」で紹介された。このアーキテクチャは、トランスフォーマーのエンコーダー部分を取り除いた、デコーダーだけの構成であった。

2018年当時の標準的な手法は、ラベルなしデータで「事前トレーニング」を行い、その後特定のタスクに特化したファインチューニングを適用するというものであった。GPTはファインチューニング後、そのファインチューニングを行った単一のタスクにおいてのみ優れた能力を発揮した。

GPT-2（2019年）では、モデルサイズ（GPTの1億1700万個に対し15億個のパラメータ）とトレーニングデータセット（GPTの4.5 GBに対し40 GB）の大幅な増加により、前例のない特性が現れた。GPT-2は特定のタスクに対してファインチューニングする必要がなく、事前トレーニング済みモデルをそのまま適用しても、そのタスク専用にファインチューニングされた最先端モデルより優れた結果を出せることが多かった。

GPT-3（2020年）では、モデルサイズとトレーニングデータが再び1桁増加し（1,750億パラメータ、4,990億トークン）、能力も飛躍的に向上した。論文「Language Models Are Few-Shot Learners」では、モデルに完了してほしいタスクの例を少数（few-shot）与えるだけで、入力パターンを忠実に再現し、想像できるあらゆる言語ベースのタスクを実行できることが示された。この時、入力（プロンプト）を修正することで、必要なタスクを実行するようにモデルを条件付けできることがわかり、これが「プロンプトエンジニアリング」の誕生となった。

2022年11月にリリースされたChatGPTはGPT-3.5を基盤としており、2023年3月にはGPT-4がリリースされた。GPT-4は詳細は公式には明らかにされていないが、モデルサイズとトレーニングデータ量が再び桁違いに大きくなり、旧バージョンよりもさらに高い能力を持つと噂されている。

### 1.3 プロンプトエンジニアリング

プロンプトエンジニアリングとは、最も単純な形では、目の前の問題に対応するために必要な情報を含むように、プロンプトを巧みに作り上げるプラクティスである。LLMの本質は、テキストを補完する能力にあり、モデルへの入力は「プロンプト」と呼ばれ、これはモデルが補完することを期待するドキュメントやテキストのブロックである。

本書では、単一のプロンプトを超えて、プロンプトの構築と回答の解釈をプログラムで行うLLMベースのアプリケーション全体について、プロンプトエンジニアリングのより大きな全体像を提供する。質の高いソフトウェアと優れたユーザー体験を構築するために、プロンプトエンジニアは、ユーザー、アプリケーション、LLM間の反復的なコミュニケーションのパターンを作成する必要がある。

プロンプトエンジニアリングの科学と「芸術」は、このコミュニケーションが、ユーザーの問題空間とLLMのドキュメント空間という非常に異なる領域間で最適に変換されるように構造化されるようにすることにある。

#### プロンプトエンジニアリングの洗練度レベル

**基本レベル**
最も基本的な形式では、非常に薄いアプリケーション層のみを使用する。例えば、ChatGPTを使用する場合、ほぼ直接プロンプトを作成しており、アプリケーションは単に会話スレッドを特別なChatML形式のMarkdownでラップしているだけである。同様に、GitHub Copilotが最初にコード補完のために作成されたときは、現在のファイルをモデルに渡して補完するだけであった。

**中級レベル**
プロンプトエンジニアリングが、モデルへのユーザー入力を修正および拡張することを含む。例えば、LLMはテキストを扱うため、技術サポートのホットラインでは、ユーザーの音声をテキストに変換してLLMへのプロンプトとして使用できる。さらに、過去のサポート記録や関連ドキュメントから得られた情報をプロンプトに含めることもできる。

この洗練度レベルにおけるプロンプトエンジニアリングのもう1つの側面は、LLMとのやり取りが「ステートフル」になる、つまり以前のやり取りからのコンテキストと情報を維持する場合に現れる。チャットアプリケーションは、この典型的な例である。

さらなる側面として、LLMベースのアプリケーションにツールを提供することがある。これにより、LLMはAPIリクエストを通じて実世界とつながり、情報を読み取ったり、インターネット上のアセットを作成・変更したりできる。

**上級レベル**
本書で扱う最後の洗練度レベルは、LLMアプリケーションにエージェント機能（ユーザーが提供する広範な目標を達成する方法について独自の判断を下す能力）を提供する方法である。これは明らかにLLMの能力の最前線にあるが、研究と実践的な探求が進行中である。すでにAutoGPTをダウンロードして目標を設定すれば、その目標達成に必要な情報を集めるための多段階プロセスを自動的に実行できる。

## まとめ

第1章では、プロンプトエンジニアリングの世界への導入として、LLMの歴史的発展とプロンプトエンジニアリングの概念について学んだ。ChatGPTの爆発的な普及から始まり、seq2seqからトランスフォーマー、そしてGPTシリーズへの技術的進歩を辿った。

重要なのは、プロンプトエンジニアリングが単なるプロンプト作成技術ではなく、ユーザーの問題空間とLLMのドキュメント空間を橋渡しする総合的なアプリケーション開発手法であることである。基本レベルから上級レベルまでの段階的な洗練度があり、将来的にはより高度なエージェント機能へと発展していく可能性を秘めている。