# 3章: チャット形式への移行

## 主要ポイント

### RLHFの全体プロセス
- **ベースモデル** → インターネット全部読んだけど制御困難
- **SFTモデル** → 人間の模範回答で学習（約13,000件）
- **報酬モデル** → 人間がランク付けした結果を学習（約33,000件）
- **RLHFモデル** → 最終的に「有用・正直・無害」なアシスタント

### HHHアラインメント
- **Helpful（有用）**: 指示に忠実、簡潔で役立つ
- **Honest（正直）**: 虚偽情報を作らない、不確実性を明示
- **Harmless（無害）**: 偏見・危険情報・攻撃的コンテンツを生成しない

### RLHFが解決する問題

#### 正直さの問題
- SFTだけでは「知らないことをでっち上げる」
- RLHFで内部知識と矛盾する回答に低評価
- 結果：確信のある情報は自信を持って、曖昧な場合は控えめに

#### 偏りの軽減
- SFT：少数の人が回答例作成→偏りのリスク
- 報酬モデル：集団の平均的評価→より一般的な基準

### インストラクトモデルからチャットモデルへ

#### インストラクトモデルの課題
- 「補完モード」vs「インストラクトモード」が曖昧
- アラインメント税（知能の犠牲）

#### ChatMLの導入
```
<|im_start|>system
あなたは親切なアシスタントです
<|im_end|>
<|im_start|>user
質問内容
<|im_end|>
<|im_start|>assistant
```

#### ChatMLの利点
1. **明確なコミュニケーションパターン**
2. **システムメッセージでの振る舞い制御**
3. **プロンプトインジェクション防止**（特殊トークンをユーザーが生成不可）

### APIの変化
- 2023年7月時点でチャットAPIが全トラフィックの97%
- 補完API → チャットAPIへの急速なシフト

### 重要なパラメータ
- **temperature**: 創造性の制御（0.0=安全、1.0=バランス、2.0=危険）
- **max_tokens**: 出力長制限
- **stop**: 終了条件の指定
- **n**: 並行生成数

## 比喩とキーコンセプト

### プロンプトエンジニアリング = 脚本作成
- **登場人物**: system, user, assistant, tool
- **脚本家**: プロンプトエンジニア、ユーザー、LLM、外部API
- **目標**: ユーザーが満足するハッピーエンド

### チャットモデルの本質
どれだけ高度な機能が追加されても、LLMの核は「補完エンジン」
- チャット：ChatML形式のトランスクリプト補完
- ツール：関数呼び出し構文を含むトランスクリプト補完

## 実践的な学び
- **アラインメント税**: 礼儀正しさと引き換えに知能が犠牲になることも
- **費用対効果**: RLHFは比較的少ない人手で大きな改善が可能
- **プロンプトインジェクション対策**: ChatMLの特殊トークン保護機能